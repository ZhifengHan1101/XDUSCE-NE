## 1.DIKW金字塔

解释了谁跟谁的联系，理解每个概念的意义；哪些过去哪些未来

![image-20241120171030222](/Users/hzf/Library/Application Support/typora-user-images/image-20241120171030222.png)

解释了数据与信息、知识与智慧等概念之间的区别与联系；

数据（记录） -> 信息（数据反映的现象）-> 知识（多条信息中发现规律）-> 智慧（运用知识）

数据、信息、知识都是过去的，智慧是未来的



## 2.数据结构化

三种数据的含义、本质、举例都要理解

区别为是否可以用关系数据库存储和管理的数据，本质为是否按照结构收集数据、或数据是否容易结构化

![image-20241120171353822](/Users/hzf/Library/Application Support/typora-user-images/image-20241120171353822.png)



## 3.大数据的4V特征

哪4V？每个特征都是什么意思？

- 速度快：数据增长速度快，数据处理的时间要求高
- 价值密度低：数据价值与数据量之间不一定存在线性关系
- 数据量大：相对于计算与存储能力，数据量大
- 类型多：结构化、非架构化、半结构化等



## 4.大数据的本质

为什么说大数据不等同于小数据的集合？大数据的本质，四种涌现有什么、都是什么

- 因为从小数据到大数据的过程中出现了“涌现”现象，“涌现”是大数据的本质特征，即小数据集合+涌现=大数据
- 价值涌现：大数据中某个成员小数据可能无价值；但由这些小数据组成的大数据有价值
- 隐私涌现：大数据中的成员小数据可能为非敏感数据；但组成的大数据可能为敏感数据
- 质量涌现：大数据中的成员小数据可能有质量问题（缺失、冗余、垃圾）；但不影响大数据的质量
- 安全涌现：大数据中的成员小数据可能不设计安全问题（不带密级），但大数据可能影响到信息安全和国家安全（带密级）



## 5.数据层次

0123次数据，什么含义、怎么处理实现递进

原始数据 ---(预处理)---> 干净数据 ---(分析处理)---> 增值数据 ---(处理至可用于决策)---> 洞见数据

![image-20241120173258414](/Users/hzf/Library/Application Support/typora-user-images/image-20241120173258414.png)



## 6.三元素原则

那三个原则？3C精神、VN图表示的关系

数据科学：理论、实践、精神（3C的交集）的交集

3C精神：Creative Working, Critical Thinking, Curious Asking

 ![image-20241120173953386](/Users/hzf/Library/Application Support/typora-user-images/image-20241120173953386.png)



## 7.KNN

KNN的原理搞懂，给题要能算；欧氏距离、曼哈顿距离；例子题手推一遍

原理：有标签数据首先训练好模型；之后输入一个未知标签的数据时，将新增数据的特征与样本集中的样本特征进行对比分析，并计算出特征最相近的k个样本（k个近邻），最后选择k个最相似样本数据中出现最多的“分类标签”作为新增数据的“分类标签”

```python
# 欧氏距离思想
def euclidean_distance(x1, x2):
     return math.sqrt(np.sum((x1 - x2)**2))
 
# 曼哈顿距离思想
 def manhattan_distance(x1, x2):
     return np.sum(np.abs(x1 - x2))
```

![image-20241121002109970](/Users/hzf/Library/Application Support/typora-user-images/image-20241121002109970.png)

![image-20241121002121203](/Users/hzf/Library/Application Support/typora-user-images/image-20241121002121203.png)



## 8.遗传算法

三个基本算子（选择交叉突变）都有什么意义、基本思想是啥、要知道每次迭代都选出适应度最高的后代，再去产生后代，替代现有成员。（问的可能是方方面面，滚吧）

- 选择：适者生存，通过优胜劣汰，确保下一代整体上比上一代更优，从而使算法逐步逼近最优解
- 交叉：核心操作，通过两父代繁衍生成新的个体，在解空间上探索更多潜在解
- 突变：引入随机性和多样性，防止算法陷入局部最优，增强种群的探索能力

基本思想：每一次迭代选出总体中适应度最高的成员来产生后代，替代总体中适应度最差的成员



## 9.强化学习

主要思想是啥、两部分是啥、三要素是啥、举个例子网安领域哪里可以用强化学习解决问题

思想：agent在envirionment中学习，根据state执行action，并根据reward反馈来指导更好的动作

- 两部分：agent、environment

- 三要素：state、action、reward

网安例子：Web防火墙规则优化。在Web安全中，防火墙规则的设置直接影响到拦截恶意请求的效果和正常业务的可用性。强化学习可以用来优化防火墙规则，确保拦截恶意请求的同时尽量减少对正常请求的干扰。

- Agent：Web防火墙规则优化器
- Environment：Web流量环境，包括正常请求和恶意混合流量
- State：当前防火墙状态和流量统计特征
- Action：防火墙的规则设置
- Reward：根据拦截结果给智能体的反馈

![image-20241121010007998](/Users/hzf/Library/Application Support/typora-user-images/image-20241121010007998.png)



## 10.机器学习面临的主要挑战

每个挑战啥意思也要写

- 过拟合：学习到的目标函数在训练集上的准确率很高，在测试集的准确率很低。（使用交叉验证法验证）
- 维度灾难：算法在低维空间表现好，高维数据效果差或效率低
- 特征工程：在机器学习前需要对训练集的特征进行分析。但在实际数据处理任务中，往往需要自动完成特征信息的分析和提取工作
- 算法的可拓展性：需要重视训练集的可拓展性，需要平衡训练集的规模、目标函数的复杂度、机器学习算法的运行效率三者的矛盾
- 模型集成：学习多个模型，并对这些模型进行集成处理。（直接集成法、增强法、堆叠法）



## 11.元分析法

意义、定义、常用方法：加权平均、优化方法

定义：在已有统计分析结果的基础上进一步进行统计分析的方法，用于二次、三次数据

- 加权平均法：统计若干按照时间顺序排列起来的、某一变量的观测值，并把这段时间出现的次数作为权数，计算加权算术平均数
- 优化方法：从备选方案中挑一个“最优方案”。（三要素变量、约束条件、目标函数，规划求最优解问题）



## 12. 数据科学的基本流程

是啥？数据化是啥、对应哪一次数据；什么是干净数据、规整数据，定义能答出来，能举例子和区别与联系；

数据化：捕获人们的生活、业务或社会活动，并将其转换为数据的过程，这个数据为原始数据，也为零次数据

干净数据：主要代表数据质量是否有问题、如缺失值、错误值、噪声信息

规整数据：主要代表数据的形态是否符合计算与算法要求

![image-20241121014412747](/Users/hzf/Library/Application Support/typora-user-images/image-20241121014412747.png)



## 13.数据审计

数据审计方法3类，意义和例子；脏数据是啥：缺失数据、冗余数据、噪声数据，给现象问属于某类，这三类有啥不一样，这三类的各自处理手段（对于分箱，等深、等宽、怎么算）

#### 预定义审计

来源数据带有自描述性验证规则时，可以通过查看系统的设计文档、实现代码或试验方法找到这些验证规则，即简单的结构化数据sql筛选，数据完整性、格式、重复值检测，例子：

数据字典、

用户自定义的完整性约束条件（sql数据库，select * from table where 年龄 >= 20 and <= 40）、

数据的自描述性信息，如数字指纹（数字摘要）、校验码、XML Schema定义、

属性的定义域与值域、

数据自包含的关联信息

应用：检查字段是否有空值、重复值；验证数据类型和格式是否符合预期；数据完整性校验（主键是否唯一）



#### 自定义审计

来源数据缺少自描述性验证规则时，需要自定义规则来审计。在sql上自定义一个搜索规则，复杂逻辑和跨表关联的业务规则演这个，例子：

变量定义规则，在单（多）个变量上直接定义的验证规则，如：给定一个有效值（无效值）的取值范围；或者列举所有有效值或无效值

函数自定义规则：对变量进行函数定义

其他自定义规则

应用：检查数据是否满足特定的业务规则（如销售额大于0时，订单状态必须为“已完成”）；验证跨表关联数据的一致性（如客户表和订单表中客户ID匹配）



#### 可视化审计

难以用统计学和机器学习方法发现数据问题时，通过可视化工具展示数据分布。

应用：可视化检测数据分布是否符合预期、发现极值或异常点



#### 脏数据

指数据审计活动中发现有质量问题的数据，分为

- 缺失数据

  - 处理方法：忽略、删除、插值

  - 处理步骤：数据审计识别缺失数据；缺失数据的分析，特征分析、影响分析、原因分析；缺失数据的处理，忽略、删除、插值

- 冗余数据：重复数据、不相关数据

  - 处理方法：数据过滤

  - 处理步骤：审计识别、冗余数据分析、分别过滤

- 噪声数据：错误数据、虚假数据、异常数据；测量变量中的随机错误或偏差
  - 处理方法：分箱、聚类、回归

#### 分箱

等深分箱：每个箱的数值数量相同

等宽分箱：每个箱的数值范围相同

对于Score={60,65,67,72,76,77,84,87,90}

![Page1](/Users/hzf/Downloads/Page1.jpg)

![Page2](/Users/hzf/Downloads/Page2.jpg)



## 14. 标准化

为什么需要标准化？01标准化、z-score标准化是什么，优缺点，公式

- 多指标评价体系中，各评价指标通常有不同的量纲和数量级。如果不同指标间直接比较分析，会突出数值较高的指标作用，而削弱数值水平较低指标的作用
- 保证结果的可靠性
- 加快模型的收敛速度



#### 0-1标准化

对原始数据进行线性变换，使结果落到$[0,1]$。
$$
x^*=\frac{x-min}{max-min}
$$
优点：简单直观，数值限定在特定范围内

缺点：受极端值影响大，不能处理分布不同的数据

#### z-score标准化

将原始数据转换为标准正态分布，即均值为0，标准差为1。
$$
z=\frac{x-μ}{σ}
$$
优点：不受极端值影响，适用于大多数机器学习算法

缺点：不限制数据范围



## 15. Google三大论文

在云计算和大数据技术领域产生深远影响的三篇论文：

- GFS论文
- MapReduce论文
- BigTable论文



## 16. MapReduce

基本思想、分为哪几步（6、5都可以）、方方面面、工作流程、工作原理

#### 思想

1.分布式计算模型：Google提出，用于处理大规模数据集

2.输入和输出格式：数据以<key, value>形式表示

3.计算阶段：Map阶段，将任务分解成子任务，分别由不同节点处理；Reduce阶段，对Map阶段的输出进行聚合和总结

4.函数抽象：通过用户自定义的map()和reduce()函数完成计算



#### 工作流程

1.输入文件：输入文件分为M个数据块，每个数据块的大小一般为16MB-64MB

2.Map阶段：每个Map Worker读取数据块，提取出<key, value>并传递给map()函数处理，处理后生成中间的<key, value>，暂存在内存中

3.中间处理：缓存中的<key, value>通过分区函数分成R个分区，并周期性的写入本地磁盘。数据由Master管理并通知Reduce Worker

4.Reduce阶段：Reduce Worker从Map Worker拉取相关分区数据。数据根据Key进行排序(内存外存都可)，以确保具有相同Key的记录聚集在一起。Reduce Worker将排序后的数据传递给reduce()函数。

5.输出文件：输出结果写入到R个分区的输出文件中，每个Reduce任务产生一个输出文件，文件名用户指定。所有的Map和Reduce任务都完成以后，Master唤醒用户程序，用户程序可调用MapReduce的返回值



![image-20241121173948898](/Users/hzf/Library/Application Support/typora-user-images/image-20241121173948898.png)



#### 应用

分布式grep、分布式排序、Web访问日志分析、反向索引构建、文档聚类、机器学习、数据分析、基于统计的机器翻译、生成整个搜索引擎的索引

#### 特征

- 以主从结构的形式运行
- map函数和reduce函数之间的数据处理
- <key, value>类型的输入/输出
- 数据存储位置的多样性
- 容错机制的复杂性：Master会周期性ping Worker，如果约定时间内没有收到回复，任务会重新调度；Master负责将map键值对的中间结果的存储位置写入磁盘，告知Reduce Worker，因此会设置检查点，按照最后一个检查点启动另一个Master进程
- 任务粒度大小的重要性：M个Map，由输入数据的分片数决定，每个独立处理16-64MB的输入数据；R个Reduce，由用户指定，一般为Worker机器数的倍数。Master必须执行O(M+R)次调度，并且在内存中保存O(M*R)个状态
- 任务备份机制的重要性：有一些慢节点会拖累整体执行速度，使用“推测性执行”的任务备份机制解决，当作业中大多数任务已经完成时，系统在几个空闲的多个Worker上调度执行剩余任务的拷贝



## 17. Hadoop

是什么？包含HDFS的讲解。是什么、架构是啥、那些东西组成的、MapReduce扮演什么角色、HDFS扮演什么角色、YARN怎么控制

Hadoop：在分布式服务器集群上存储海量数据并运行分布式分析应用的一个开源软件框架

包含核心组件：

HDFS：负责分布式存储，支持超大文件（小文件处理能力反而较弱）、基于商用硬件（廉价、可靠性不高的普通商用硬件）、流式数据访问（一次写入，多次读取）、高吞吐量（同时数据延迟访问）

MapReduce：负责分布式计算，执行并行化任务

YARN：负责资源管理和任务调度

![image-20241121221635899](/Users/hzf/Library/Application Support/typora-user-images/image-20241121221635899.png)



## 18.Spark

是啥？有了MapReduce为啥还要Spark？Spark特点大概记一下

Spark是一个快速的、多用途的集群计算系统，相对于MapReduce将中间结果保存在磁盘中，Spark使用内存保存中间结果，能在数据尚未写入硬盘时在内存中进行计算

#### 为什么要Spark？

- MapReduce：计算过程比较缓慢（涉及大量的磁盘读写），不适应交互计算、迭代计算（批处理框架，无法快速响应用户需求）；不是所有计算都由Map和Reduce两个阶段组成
- Spark：计算速度更快（内存存储中间结果，迭代计算避免磁盘多次读写大大加速），提供更好的API（更灵活的编程模型），高效地资源利用（可以运行在Hadoop YARN之上，无缝兼容），更强的交互性（支持交互式的Shell环境）

#### Spark特点

速度快

易用性：支持多种语言的API

通用性：提供完整的技术栈

兼容性：可以运行在Hadoop YARN等各种集群中



## 19. Spark和Hadoop的异同

Spark和Hadoop之间的区别和联系，适用的类型场景。以及三者的区别联系

![image-20241122021504007](/Users/hzf/Library/Application Support/typora-user-images/image-20241122021504007.png)



## 20. SQL常用语句

给两张表，从中筛选信息。课件上的红色的各种查询，总之会用SQL语句按照题目要求把表格里面的信息拿出来

```sql
# 条件查询
select * from <table> where <condition>;
select * from students where score >= 80 and gender = 'M';
select * from students where not class_id = 2;

# 投影查询
select col1, col2, col3,... from <table>

# 排序
order by xx
order by xx desc	# 降

# 聚合查询
select dep_id, avg(salary) as ave_salary from employees group by dep__id

# 多表查询
select e.employee_id, e.name, d.department_name
from employees e, department d
where e.department_id = d.department_id

# 链接查询
select e.employee_id, e.name, d.department_name
from employees e
join department d
on e.department_id = d.department_id
# 其中on表示连接条件，如果需要进一步筛选，后面再连接where
```



## 21. 数据可视化

什么是数据可视化？科学、信息可视化特点、区别是啥？给个例子用啥可视化。一个图表示什么

数据可视化：狭义上，数据可视化主要处理统计图形、抽象地理信息或概念模型的空间数据，与科学可视化、信息可视化和可视分析学并列；广义上包括科学可视化、信息可视化和可视分析学

科学可视化：最早出现；**面向自然科学领域**；规范化和标准化程度较高；结果一致性，对同一数据的可视化方法和结果基本相同

![image-20241123181136715](/Users/hzf/Library/Application Support/typora-user-images/image-20241123181136715.png)

信息可视化：问题导向，注重特定问题的解决；个性化程度高，结果可以因需求不同而差异化；应用范围广泛，涉及时空数据可视化、文本信息可视化、多媒体数据可视化等领域

![image-20241123183859208](/Users/hzf/Library/Application Support/typora-user-images/image-20241123183859208.png)



## 22. 视觉假象

含义是啥，造成的原因，为啥存在

含义：在数据可视化中，目标用户产生错误的或不准确的视觉感知，而这种感知与数据可视化设计者的意图或数据本身的真实情况不一致。

原因：

- 上下文（周边环境）影响：可视化视图所处的上下文可能导致视觉假象。例如，视觉编码（将数据映射为视觉形式）与视觉通道（如颜色、亮度、形状等）可能收到周围环境的干扰
- 相对判断错误：人们对亮度和颜色的相对判断容易出错，导致对数据的误解。例如背景或邻近的色彩影响人们对目标色彩的感知
- 用户的经历与经验：目标用户的个人经历和认知经验可能影响其对图标的解读。例如，一个有特定文化背景的人可能对某些符号和颜色的理解不同

![image-20241123193113602](/Users/hzf/Library/Application Support/typora-user-images/image-20241123193113602.png)

![image-20241123193124768](/Users/hzf/Library/Application Support/typora-user-images/image-20241123193124768.png)

![image-20241123193143994](/Users/hzf/Library/Application Support/typora-user-images/image-20241123193143994.png)



## 23. 数据故事化

是啥？为啥需要？情景分为三类

定义：为了提升数据的可理解性、记忆性及可体验性，将“数据”还原或关联至特定的“情景”的过程

为什么需要：提升数据的可理解性、增强数据的可记忆性、提高数据的可体验性

情景：

- 还原情景（还原数据所计量和记录信息时的“原始情景”）
- 移植情景（将数据移植到另一个真实发生的情景中，而非原始情景）
- 虚构情景（讲述虚构的、并未真实存在的情景）



## 24. 数据产品

是啥？列举存在形式

定义：数据产品是指能够通过数据帮助用户实现某一个或多个目标的产品

存在形式：数据集、文档、知识库、应用系统、硬件系统、服务、洞见、决策、或他们的组合



## 25. 数据柔术

是啥、含义、难点；风险评估、风险应对策略要能答出来；数据开发过程中考虑三个指标，什么场景使用哪个指标

定义：将数据转换为产品的艺术

难点：如何借助目标用户的力量来解决产品中的难题；产品要有艺术性、以目标用户为中心的产品开发

- 数据产品的开发需要识别各类风险，进行**风险评估**和**风险应对策略**，并积极制定应急预案

三个指标：

- 查全率：系统从所有可能相关的内容中，成功检索出相关内容的比例。搜索引擎中的图书类广告信息（希望尽可能看到更多图书广告，目标是全面）
- 查准率：系统检索出的内容中，实际相关内容的比例。搜索引擎中的餐饮类广告信息（餐饮更注重是否匹配喜好，要准不要多）
- 响应时间：搜索引擎中的返回结果，优化响应时间



## 26. 大数据常见安全问题

- 数据安全：数据安全不等于数据保密
- 数据偏见：数据来源选择偏见、数据加工和准备偏见、算法和模型选择偏见，避免偏见进偏见出
- 算法歧视：算法设计、实践和投入使用过程中出现歧视现象。“大数据杀熟”
- 数据攻击：攻击者通过技术手段窃取、 篡改或破坏数据。“谷歌炸弹”利用搜索算法漏洞提升特定内容的排名
- 隐私保护：确保不愿公开的信息不被泄露



## 27. P2DR

四个组成部分，每个部分的含义

- Policy（安全策略）：明确系统安全的总体规划。定义系统的监控周期、确立系统的恢复机制、指定网络访问控制策略和明确系统的总体安全规划和原则
- Protecion（防护）：预防恶意威胁，定期检查脆弱性。预防安全事件的发生、定期检查系统的脆弱性、防止意外威胁、防止恶意威胁
- Detection（检测）：发现潜在威胁，实时监控安全状态。发现新的威胁和弱点，与防护系统形成互补
- Response（响应）：系统一旦检测到入侵，响应系统进行事件处理



## 28. 网络传感器

根据哪三方面分类？每个属性分别用来表示啥？（视点用来表示xxx，都能答出来）每一领域内的传感器都能用哪几种不同的行动来处理数据（报告、事件。。。啥时候用啥，定义啥意思）

#### 分类

- Vantage（视点，检查点）：用来表示传感器在网络中的排布方式。能够确定传感器的布局位置，影响传感器所能捕获数据的类型及覆盖范围。比如路由器与交换机接口上的传感器、集线器的所有流量、某主机的HTTP日志数据
- Domain（领域）：用来表示传感器所提供的是哪方面的信息。
  - 网络领域（Network）：捕获网络包（如PCAP、NetFlow），实时，采集IP和MAC地址相关信息
  - 服务领域（Service）：采集日志数据（如Web服务日志），实时，记录服务事件及基于服务的ID
  - 主机领域（Host）：收集系统状态及特征警告（如CPU使用率），异步，记录数据中的IP、MAC、UUID
  - 主动领域（Active）：分析者主动驱动，如扫描网络获取IP地址和服务ID
- Action（行动）：用来表示传感器会怎样报告相关的信息。
  - 报告（Report）：只给出log，把自己观察到的现象都描述出来，仅提供记录的原始数据，无法进一步处理。网络分析工作中所需的很多基本数据都需要报告传感器收集。NetFlow collector、tcpdump、服务器日志等
  - 事件（Event）：给出结论，从多个数据源中收集数据并产生事件，对某些数据作出概括，基于收集到的数据生成具体事件。入侵检测系统IDS、杀毒传感器
  - 控制（Control）：作出反应，从多个数据源中收集数据并作出判断，再决定作何反应，分析数据后作出反应，如修改或阻止网络流量。防火墙、入侵预防系统、反垃圾邮件系统、某些反病毒系统

![image-20241124155107100](/Users/hzf/Library/Application Support/typora-user-images/image-20241124155107100.png)

## 29.入侵检测系统

什么是？IDS分类、常用评价指标有哪些

定义：IDS是一种网络安全设备，用于实时监控网络传输，在发现可疑行为时发出警报或采取相应措施。

是一种积极主动的安全防护技术、通常以二元分类器的形式出现、与入侵预防系统（IPS）不同，IDS只负责检测，IPS会进一步阻断可以流量

#### 分类

- 按照所在领域
  - 基于网络的IDS：监控网络中的流量
  - 基于主机的IDS：监控主机的流量
- 按照做决策时的依据
  - 基于特征的IDS
    - 根据特征来匹配（如恶意代码、网络攻击模式等）
    - 当可供判断的特征规则比较少时，对未知攻击经常漏报，表现出伪阳性
  - 基于异常的IDS
    - 学习正常行为，检测偏离正常模式的活动
    - 当学习到的正常行为比较少时，经常发生误报，表现出伪阳性

#### 指标

- 误报（伪阳性）：正常判异常。第一型错误，系统将正常行为判别为攻击行为的比率
- 漏报（伪阴性）：异常判正常。第二型错误，系统未能检测到实际存在的攻击行为的比率
- 灵敏度：异常判异常。系统在所有真实的攻击行为中，正确检测到的比率
- 特异度：正常判正常。系统在所有正常行为中，判定为正常的比率



## 30. 中间盒middlebox

什么是，常见的有哪些，其中某一个介绍工作原理，画图讲工作原理

定义：middlebox是一种位于网络中间的计算机网络设备，其功能不仅仅是数据包的转发，还包括转换、检查、过滤和操作数据包，用于实现特定目的。

#### 常见的middlebox

防火墙、IDS、IPS、NAT、负载均衡器、WAN optimizer

#### 原理

- VPN：通过加密和认证技术在公共网络上建立安全通信的机制

  - 隧道技术：VPN利用隧道协议将数据在发送端和接收端之间建立虚拟加密通道，通过封装数据包，隐藏真实内容
  - 加密传输：发送数据前对其进行加密，以防数据在传输过程中被窃取或篡改，常用的加密协议包括IPSec、SSL/TLS
  - 身份认证：VPN通过用户凭证（用户名、密码或证书）对发送端和接收端进行认证，确保合法的设备和用户才能接入
  - 流量处理：数据包首先被发送到VPN服务器，解密后转发到目标服务器；返回的数据也会经过VPN服务器加密，再发回客户端

  ![image-20241124164339231](/Users/hzf/Library/Application Support/typora-user-images/image-20241124164339231.png)

- Proxy：代理，位于客户端和目标服务器之间的中间设备，用于转发请求和响应
  - 请求转发：客户端向代理服务器发送请求，代理服务器再将请求转发给目标服务器；请求经过代理时，可以进行过滤、缓存和加速等处理
  - 响应返回：目标服务器将响应返回给代理服务器，代理服务器再将其转发给客户端
  - 类型分为
    - 正向代理：用户通过代理访问外部服务器，常用于突破访问限制、隐藏用户IP等
    - 反向代理：外部用户访问代理服务器，代理服务器转发请求到内部服务器，常用于均衡负载和保护内部服务器

![image-20241124164351688](/Users/hzf/Library/Application Support/typora-user-images/image-20241124164351688.png)

- NAT：网络地址映射技术，将私有IP转换为公有IP，用于网络设备访问外部网络
  - 地址转换：通过修改IP报头，当内部网络设备向外发送数据时，NAT将设备私有IP地址替换为公共IP地址，并记录映射关系。返回的数据包根据映射表将目标地址还原为私有IP地址。
  - 端口映射：NAT设备为每个连接分为一个唯一的端口号，用于区分多个设备的通信
  - 类型：静态NAT，1v1；动态NAT，泡池子；端口地址转换，通过端口号将多个私有IP映射到一个公共IP

![image-20241124165114488](/Users/hzf/Library/Application Support/typora-user-images/image-20241124165114488.png)



## 31. 异常检测

什么是？和新奇检测有啥区别？能判断哪个是哪个。异常检测的挑战

定义：异常检测是指在数据中发现不符合预期行为模式的数据的问题，这些不符合的模式通常被称为异常、异常值、不一致的观察结果、例外等。

#### 区别

- 异常检测分析同时包括正常值和异常值的数据；新奇检测主要设计使用不包含任何异常值的数据来表示“常规”数据
- 异常检测适合处理已知的异常和正常行为；新奇检测适合检测从未见过的新行为或模式
- 异常检测的目标是找到异常模式；新奇检测的目标是找到与正常模式显著不同的行为

#### 挑战

- 未知性：异常检测涉及许多未知因素，很难预定义异常的所有特征，因此需要灵活的检测算法
- 异常类的异构性：异常通常是不规则的，同一类异常可能表现出完全不同的特征。导致 模型难以通过单一规则覆盖所有的异常模式
- 类别不均衡：异常通常是稀少的实例，正常实例占大多数；类别不平衡导致模型更容易倾向于正常类别，增加漏报的可能性

## 32. 自相关

啥意思，能够描述（公式、机理），啥时候能用

自相关是时间序列分析中的一个重要概念，表示一个时间序列与其自身在不同时间间隔上的相关性。它用于度量序列中一个值与其先前值之间的相关程度。自相关越高，时间序列预测效果越好。

公式：$$r_k = \frac{\sum_{t=1}^{n-k} (x_t - \bar{x})(x_{t+k} - \bar{x})}{\sum_{t=1}^n (x_t - \bar{x})^2}$$

#### 机理

- 滞后性：时间序列数据往往具有时间上的依赖性，自相关通过计算一个值与其滞后值的相关性来反应这种依赖性
- 周期性：如果时间序列中存在周期性趋势，自相关系数在某些滞后值上会表现出较高的相关性
- 平稳性：自相关通常用于平稳时间序列分析，非平稳序列需要进行差分或转换以消除趋势和季节性

#### 应用场景

- 时间序列模型选择：AR和ARIMA，根据自相关图或偏自相关图选择滞后项
- 季节性与周期性分析：检测时间序列中是否存在重复的周期性模式
- 信号处理
- 异常检测：自相关可以帮助识别时序数据中的偏离现象



## 33. 网络防御技术

有哪些？（入侵检测巴拉巴拉）每个技术都是啥意思、应用场景。访问控制功能有哪些？访问控制的分类。微分段是什么？什么时候用？什么是蜜罐技术？什么是蜜网技术？他们的区别？

- 访问控制
  - 功能
    - 认证：验证用户身份，确保只有合法用户可以访问系统。常用方式有，密码、指纹识别、虹膜识别等
    - 授权：根据用户身份分配相应的资源使用权限，确保不同用户仅能访问与其身份匹配的资源
    - 文件保护：附加对文件的安全保护，防止非授权用户读取或修改
    - 审计：记录用户操作日志，以便时候追溯和验证安全策略的有效性。支持数据筛选并生成审计报告
  - 分类
    - 自主访问控制：用户对自己创建的资源有完全控制权，可以授予或拒绝他人访问
    - 强制访问控制：系统以统一的安全策略对用户访问资源进行强制性控制
    - 基于角色的访问控制：根据用户角色分配访问权限
    - 基于属性的访问控制：根据用户和资源的属性来动态调整访问权限
    - 基于任务的访问控制：权限随用户执行的任务动态变化，适合同态流环境
    - 基于对象的访问控制：访问控制与具体资源对象直接关联，如为每个对象单独定义权限规则
- 入侵检测：通过被动观察来检查网络破坏。截取源和目的地之间的直接通信线路，并对检测到的异常自动采取行动。用于网络流量监控，检测非法流量或异常访问；边界保护，对边界网络执行深度分析，实时发现攻击
- 蜜罐技术：蜜罐是一个伪装成真实目标的系统，用于诱骗攻击者，并记录其行为。
  - 收集攻击行为模式，转移攻击者资源，减少对真实系统的威胁。
  - 数据量较小，仅收集针对蜜罐的流量，误报率低，大多数流量为恶意行为
  - 用于研究新型攻击行为，改进入侵检测系统
- 蜜网技术：蜜网是由多个蜜罐组成的网络环境，模拟更加复杂的攻击场景。
  - 提供更加真实的攻击场景，分析分布式攻击行为
  - 使用真实计算机和网络环境，数据更加丰富，覆盖面更广
  - 研究高级持续性威胁，分析DDos攻击行为

- 蜜罐与蜜网的区别
  - 组成：蜜罐为单个虚拟或真实的系统，模拟特定的目标系统或服务；蜜网是多个互联的蜜罐组成的网络系统，隐藏在防火墙后面，使用不同的操作系统及设备并运行不同的服务
  - 原理：蜜罐通过把系统的脆弱性暴露给入侵者或是故意使用一些具有强烈诱惑性的假信息来诱骗入侵者。蜜网是在入侵检测的基础上实现入侵诱骗的，与蜜罐的理论差别很大
  - 复杂性：蜜罐中的系统通常不是完整的操作系统和应用程序，而是根据需要进行简化和定制；蜜网中的所有系统都是标准的机器，上面运行的都是真实完整的操作系统及应用程序

- 以数据为中心的安全性：加密存储数据（同态加密）
- 微分段：是将网络基于逻辑功能划分为多个小的子网络，每个子网络都有自己的安全策略
  - 功能：限制攻击者在网络中的活动范围、提高网络的可管理性和安全性
  - 什么时候用：
    - 复杂网络环境：精细化安全管理
    - 关键资源保护：需要将高敏感性资源和普通资源隔离
    - 防止横向移动攻击：限制攻击者在网络内横向移动



## 34. 被动攻击、主动攻击

有啥特点、区别

被动攻击：窃密攻击，通过截取数据包或流量分析，从而窃取重要的敏感信息。典型攻击方式是网络窃听、流量分析、端口扫描

主动攻击：涉及修改数据流或创建错误的数据流，包括漏洞、伪造（DNS欺骗、ARP欺骗）、转移、Dos和篡改消息等

区别：

- 主动攻击以破坏数据和破外服务为目的，破坏性大，容易被发现；被动攻击以窃取信息为目的，难以被发现，因此预防很重要
- 防止被动攻击的主要手段是数据加密和网络监控；防止主动攻击的主要手段是入侵检测、漏洞修补、访问控制等
- 被动攻击不直接与网络节点交互，主动攻击修改、干预网络数据



## 35. 机器学习在网络空间安全的应用流程

六个阶段

- 安全问题抽象：将网络空间安全问题映射为机器学习能够解决的类别（分类、聚类、降维）
- 数据采集：自行采集数据+公开数据集
- 数据预处理及特征提取：对原始数据进行清洗和处理
  - 数据预处理
  - 数据缺失处理及异常值处理
  - 非平衡数据处理（异常样本和正常样本数量不平衡；欠采样和过采样）
  - 数据集分割（训练集、验证集、测试集）
  - 特征提取
- 模型构造：中心环节，算法选择和参数调优
- 模型验证：评估训练的模型是否有效。最常用k倍交叉验证法
- 效果评估：关注模型的学习效果以及泛化能力

![image-20241124202854002](/Users/hzf/Library/Application Support/typora-user-images/image-20241124202854002.png)

## 36. 机器学习模型攻击

分为哪三类、啥意思，讲清楚

- 诱导攻击：攻击者借助向训练数据加入毒化数据等手段，影响模型训练过程，进而干扰模型的工作效果
- 逃逸攻击：攻击者在正常样本的基础上人为的构造异常输入样本，致使模型在分类或决策时出现错误，达到规避检测的攻击效果
- 探索攻击：攻击者试图推断机器学习模型是如何工作的，包括对模型边界的预测、训练数据的推测等



## 37. 对抗样本攻击

按攻击效果分类、功能分类；对抗样本显著特点

攻击效果分类：目标攻击&非目标攻击

攻击能力分类：白盒攻击&黑盒攻击

对抗样本显著特点：隐蔽性&可传递性



## 38. 针对深度学习的对抗攻击和中毒攻击

发生阶段、作用原理。什么是数据中毒攻击，什么是模型中毒攻击，他们的优缺点

- 中毒攻击

  - 模型训练阶段：中毒样本注入训练数据集、训练完成的深度学习模型中嵌入后门触发器、测试阶段输入毒化样本则触发攻击
  - 类标中毒攻击：修改训练数据的标签（A改成B），使模型学习错误分类
  - 数据中毒攻击：将中毒数据与正常数据一起训练，使模型学习到错误模式
    - 优点：实现简单，无需修改目标模型的网络结构，可以直接通过训练和再训练等方式实现攻击；通用性强，可以对大部分模型进行攻击
    - 缺点：可能存在不知道哪些模型会中毒的问题；通过数据清洗、异常检测可能过滤掉中毒样本
  - 模型中毒攻击：攻击者直接向用户提供已经被中毒的模型，无需依赖训练数据
    - 优点：可以获得更好的攻击效果，攻击稳定
    - 缺点：应用范围相对狭窄，需要模型被用户直接采用

  - 防御原理：1.数据及特征修改防御，预处理去除异常数据；2.模型修改防御，模型进行修改，去除毒数据训练影响；3.输出防御，对模型的输出结果进行分析，修正结果

- 对抗攻击
  - 模型测试阶段：攻击者在原始数据上设计微小扰动得到对抗样本，对深度学习模型进行愚弄；使其输出错误预测，目标可能包括逃避检测（如恶意软件分类系统），或使模型以高置信度输出错误类别



## 39. 谈一谈研究展望

瞎写但不要完全瞎写

- 提升效率
- 提高准确率
- 提升普适性
- 降低复杂度
- 保护用户隐私
